{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"basics/","text":"Basics","title":"Basics"},{"location":"basics/#basics","text":"","title":"Basics"},{"location":"basics/instrumented_testing_basics/","text":"Instrumented testing Instrumented tests are usual junit tests, but with one peculiarity: They can be launched on Android device only. Using them, you may check how your application communicates with Android OS. However, they are written and executed much slower. 1. Tests location Unlike regular jvm tests, instrumented tests located in different src: androidTest Why different src? You need to write code which describes a communication between your application and android device. For instance, clicking some buttons and checking that particular content has been shown, etc. All that code should be compiled, somehow installed on the device and should make yours application to trigger the checks you need. This code can't be a part of testSrc , because of that case we run it on JVM . There is no information about everything related to android. Every Android SDK class instance used in JVM test will be stubbed. In androidSrc we have a real knowledge about Android SDK 2. How tests run under the hood To be able to run your tests on CI and make it a part of CD , it's really important to understand how it works under the hood. 2.1 Build To test our application, we need to build it. We can do that with gradle: # It will build an apk file located in app/build/outputs/debug/debug.apk ./gradlew assembleDebug However, it's not enough for us. Remember? We also need to take care of the code we write in androidTestSrc . It also should be built and will be represented as an apk: # It will build an apk file located in app/build/outputs/debug/debug.apk ./gradlew assembleDebug # It will build an apk file located in app/build/outputs/androidTest/instrumented.apk ./gradlew assembleDebugAndroidTest We've got 2 apks: Application and Test application , which can communicate with Application 2.2 Install To do that, we need to use adb adb install debug.apk adb install instrumented.apk 2.3 Run For running instrumented tests, AndroidJunitRunner is responsible As an input, you need to provide tests you want to run. As an output, JunitReport.xml will be provided All you need to do it's to execute adb command: adb shell am instrument -w -m -e debug false \\ -e class 'com.alexbykov.myapplication.ExampleInstrumentedTest#myTest' \\ com.alexbykov.myapplication.test/androidx.test.runner.AndroidJUnitRunner We need to provide some information about tests needed to be launched: particular class, class with method or package. After execution, you may find junit report in app/build/test-results/ It's also possible to define your own instrumented arguments and get them in tests: //add -e myKey \"test\" to adb command InstrumentationRegistry . getArguments (). getString ( \"myKey\" , \"value\" ) 3. Tests location Official documentation 3. Instrumented testing types UI Screenshot Migration They are not a replacement of each other, they are complement to each other","title":"Instrumented testing"},{"location":"basics/instrumented_testing_basics/#instrumented-testing","text":"Instrumented tests are usual junit tests, but with one peculiarity: They can be launched on Android device only. Using them, you may check how your application communicates with Android OS. However, they are written and executed much slower.","title":"Instrumented testing"},{"location":"basics/instrumented_testing_basics/#1-tests-location","text":"Unlike regular jvm tests, instrumented tests located in different src: androidTest","title":"1. Tests location"},{"location":"basics/instrumented_testing_basics/#why-different-src","text":"You need to write code which describes a communication between your application and android device. For instance, clicking some buttons and checking that particular content has been shown, etc. All that code should be compiled, somehow installed on the device and should make yours application to trigger the checks you need. This code can't be a part of testSrc , because of that case we run it on JVM . There is no information about everything related to android. Every Android SDK class instance used in JVM test will be stubbed. In androidSrc we have a real knowledge about Android SDK","title":"Why different src?"},{"location":"basics/instrumented_testing_basics/#2-how-tests-run-under-the-hood","text":"To be able to run your tests on CI and make it a part of CD , it's really important to understand how it works under the hood.","title":"2. How tests run under the hood"},{"location":"basics/instrumented_testing_basics/#21-build","text":"To test our application, we need to build it. We can do that with gradle: # It will build an apk file located in app/build/outputs/debug/debug.apk ./gradlew assembleDebug However, it's not enough for us. Remember? We also need to take care of the code we write in androidTestSrc . It also should be built and will be represented as an apk: # It will build an apk file located in app/build/outputs/debug/debug.apk ./gradlew assembleDebug # It will build an apk file located in app/build/outputs/androidTest/instrumented.apk ./gradlew assembleDebugAndroidTest We've got 2 apks: Application and Test application , which can communicate with Application","title":"2.1 Build"},{"location":"basics/instrumented_testing_basics/#22-install","text":"To do that, we need to use adb adb install debug.apk adb install instrumented.apk","title":"2.2 Install"},{"location":"basics/instrumented_testing_basics/#23-run","text":"For running instrumented tests, AndroidJunitRunner is responsible As an input, you need to provide tests you want to run. As an output, JunitReport.xml will be provided All you need to do it's to execute adb command: adb shell am instrument -w -m -e debug false \\ -e class 'com.alexbykov.myapplication.ExampleInstrumentedTest#myTest' \\ com.alexbykov.myapplication.test/androidx.test.runner.AndroidJUnitRunner We need to provide some information about tests needed to be launched: particular class, class with method or package. After execution, you may find junit report in app/build/test-results/ It's also possible to define your own instrumented arguments and get them in tests: //add -e myKey \"test\" to adb command InstrumentationRegistry . getArguments (). getString ( \"myKey\" , \"value\" )","title":"2.3 Run"},{"location":"basics/instrumented_testing_basics/#3-tests-location","text":"Official documentation","title":"3. Tests location"},{"location":"basics/instrumented_testing_basics/#3-instrumented-testing-types","text":"UI Screenshot Migration They are not a replacement of each other, they are complement to each other","title":"3. Instrumented testing types"},{"location":"basics/screenshot_testing/","text":"Screenshot testing To be done","title":"Screenshot testing"},{"location":"basics/screenshot_testing/#screenshot-testing","text":"To be done","title":"Screenshot testing"},{"location":"basics/testing_theory/","text":"Testing theory","title":"Testing theory"},{"location":"basics/testing_theory/#testing-theory","text":"","title":"Testing theory"},{"location":"basics/ui_testing/","text":"UI testing To be done","title":"UI testing"},{"location":"basics/ui_testing/#ui-testing","text":"To be done","title":"UI testing"},{"location":"home/","text":"Home Despite the annual improvement of tools \u2014 everything related to Android instrumented testing still can be challenging and requires a lot of attention from engineers. The goal of this blog is to make the process of introducing instrumented testing into your team smoother and avoid repeating our mistakes. Here you will find useful practices, case and the experience of other companies.","title":"Home"},{"location":"home/#home","text":"Despite the annual improvement of tools \u2014 everything related to Android instrumented testing still can be challenging and requires a lot of attention from engineers. The goal of this blog is to make the process of introducing instrumented testing into your team smoother and avoid repeating our mistakes. Here you will find useful practices, case and the experience of other companies.","title":"Home"},{"location":"practices/emulator_vs_real_device/","text":"Emulator vs real device To be done","title":"Emulator vs real device"},{"location":"practices/emulator_vs_real_device/#emulator-vs-real-device","text":"To be done","title":"Emulator vs real device"},{"location":"practices/flakiness/","text":"Flakiness To be done","title":"Flakiness"},{"location":"practices/flakiness/#flakiness","text":"To be done","title":"Flakiness"},{"location":"practices/network/","text":"Network To be done","title":"Network"},{"location":"practices/network/#network","text":"To be done","title":"Network"},{"location":"practices/page_object/","text":"Page object How to make tests more clear and readable? Problem: There is a lot of ViewMatchers and so on in our tests once we need to find exact View . Imagine that we do have hundreds of tests that starts with pressing same button. What will be if that button would change its id? We would change ViewMatcher inside every single test. Also there is a problem if our View should be accessed with a lot of ViewMatchers used (for example when that View is a child of RecyclerView ) What should we do in the above cases? May we should extract this View to another abstraction? PageObject pattern Actually that pattern came to Android world from Web testing. This is how PageObject determined by one of its creator: The basic rule of thumb for a page object is that it should allow a software client to do anything and see anything that a human can. It should also provide an interface that's easy to program to and hides the underlying widgetry in the window. So to access a text field you should have accessor methods that take and return a string, check boxes should use booleans, and buttons should be represented by action oriented method names. www.martinfowler.com/bliki/PageObject.html Example We do have some screen with 3 Buttons Let's write some test for that screen with plain espresso @Test fun testFirstFeature () { onView ( withId ( R . id . toFirstFeature )) . check ( ViewAssertions . matches ( ViewMatchers . withEffectiveVisibility ( ViewMatchers . Visibility . VISIBLE ))) onView ( withId ( R . id . toFirstFeature )). perform ( click ()) } That test finds one of our button then checks its visibility and after that performs usual click. Main problem here \u2014 it's not easy to read. What do we want to achieve with PageObject? Ideally we want to have something like @Test fun testFirstFeature () { MainScreen . firstFeatureButton . isVisible () MainScreen . firstFeatureButton . click () } What is the difference we can see here? We use ViewMatcher inside of our test We added MainScreen abstraction that actually is a PageObject of screen provided in example isVisible() and click() are extensions (for example) As you can see that change made our code more clear and readable. And that happened even with one single test that checks visibility of button and clicks on it. Just imagine how much effort that pattern will bring to your codebase in case of hundreds tests written with PageObject Instead of writing your own implementation of PageObject pattern Just take a look for Kakao library it has a modern Kotlin DSL implementation of PageObject pattern A lot of useful classes for interact with. For example, same test for our screen written with Kakao library will look like @Test fun testFirstFeature () { mainScreen { toFirstFeatureButton { isVisible () click () } } } Conclusion PageObject pattern helps us to: \u2795 Remove duplicates of ViewMatchers from tests \u2795 Once we change id/text/whatever of View we should change it only in one place of PageObject class \u2795 New abstraction to make code more readable and clear","title":"Page object"},{"location":"practices/page_object/#page-object","text":"How to make tests more clear and readable?","title":"Page object"},{"location":"practices/page_object/#problem","text":"There is a lot of ViewMatchers and so on in our tests once we need to find exact View . Imagine that we do have hundreds of tests that starts with pressing same button. What will be if that button would change its id? We would change ViewMatcher inside every single test. Also there is a problem if our View should be accessed with a lot of ViewMatchers used (for example when that View is a child of RecyclerView ) What should we do in the above cases? May we should extract this View to another abstraction?","title":"Problem:"},{"location":"practices/page_object/#pageobject-pattern","text":"Actually that pattern came to Android world from Web testing. This is how PageObject determined by one of its creator: The basic rule of thumb for a page object is that it should allow a software client to do anything and see anything that a human can. It should also provide an interface that's easy to program to and hides the underlying widgetry in the window. So to access a text field you should have accessor methods that take and return a string, check boxes should use booleans, and buttons should be represented by action oriented method names. www.martinfowler.com/bliki/PageObject.html","title":"PageObject pattern"},{"location":"practices/page_object/#example","text":"We do have some screen with 3 Buttons","title":"Example"},{"location":"practices/page_object/#lets-write-some-test-for-that-screen-with-plain-espresso","text":"@Test fun testFirstFeature () { onView ( withId ( R . id . toFirstFeature )) . check ( ViewAssertions . matches ( ViewMatchers . withEffectiveVisibility ( ViewMatchers . Visibility . VISIBLE ))) onView ( withId ( R . id . toFirstFeature )). perform ( click ()) } That test finds one of our button then checks its visibility and after that performs usual click. Main problem here \u2014 it's not easy to read.","title":"Let's write some test for that screen with plain espresso"},{"location":"practices/page_object/#what-do-we-want-to-achieve-with-pageobject","text":"Ideally we want to have something like @Test fun testFirstFeature () { MainScreen . firstFeatureButton . isVisible () MainScreen . firstFeatureButton . click () } What is the difference we can see here? We use ViewMatcher inside of our test We added MainScreen abstraction that actually is a PageObject of screen provided in example isVisible() and click() are extensions (for example) As you can see that change made our code more clear and readable. And that happened even with one single test that checks visibility of button and clicks on it. Just imagine how much effort that pattern will bring to your codebase in case of hundreds tests written with PageObject","title":"What do we want to achieve with PageObject?"},{"location":"practices/page_object/#instead-of-writing-your-own-implementation-of-pageobject-pattern","text":"Just take a look for Kakao library it has a modern Kotlin DSL implementation of PageObject pattern A lot of useful classes for interact with. For example, same test for our screen written with Kakao library will look like @Test fun testFirstFeature () { mainScreen { toFirstFeatureButton { isVisible () click () } } }","title":"Instead of writing your own implementation of PageObject pattern"},{"location":"practices/page_object/#conclusion","text":"PageObject pattern helps us to: \u2795 Remove duplicates of ViewMatchers from tests \u2795 Once we change id/text/whatever of View we should change it only in one place of PageObject class \u2795 New abstraction to make code more readable and clear","title":"Conclusion"},{"location":"practices/shared_test_components/","text":"Shared test components To be done","title":"Shared test components"},{"location":"practices/shared_test_components/#shared-test-components","text":"To be done","title":"Shared test components"},{"location":"practices/state_clearing/","text":"State clearing This question appears as soon as you need to run more than 1 ui test. Problem: We run Test1 , it performs some http requests, saves some data to files and database. When Test1 finished, Test2 will be launched. However, Test1 left some data on the device which can be a reason of Test2 failing. Solution \u2014 clear data before each test 1. Within process clearing In this case we don't kill our application process. 1.1 Component from a real code base @Before fun setUp () { DI . provideLogoutCleanerInteractor (). clear () } The same component which clears data (For instance, while logout) . It should honestly clear everything in application: Databases, Files, Preferences and Runtime cache and should be executed before each test. Danger This solution is a bottleneck and it's better to avoid it at all. If LogoutCleaner broken, all of the tests will be failed 1.2 Clear internal storage All cache in android application stored in internal storage: /data/data/packagename/ This storage \u2014 our application sandbox and can be achieved without any permission. Common idea: to avoid usage of components from real code base and use some test rules, which do the job for us. @get : Rule val clearPreferenceRule = ClearDatabaseRule () @get : Rule val clearFilesRule = ClearFilesRule () @get : Rule val clearFilesRule = ClearPreferencesRule () They have already been implemented in Barista library, you can find them here Warning This solution won't work on 100% for you: You may have runtime cache, which is also can affect your tests Test or application process can be crashed. It prevents launch of the next tests 1.3 Conclusion \u2795 Fast implementation \u2795 Fast execution in the same process \u2796 Don't have any guarantee that your app will be cleared properly \u2796 Application or Test process killing will break tests execution \u2796 Can be a bottleneck Use these solutions only as a temp workaround, because it won't work on perspective in a huge projects 2. Clear package data Idea \u2014 simulate the same behavior when user press clear data in application settings. Application process will be cleared in that state, our application will be started in a cold start. 2.1 Orchestrator Basically it is possible to have cleared state, if you would execute your tests like this: adb shell am instrument -c TestClass#method1 -w com.package.name/junitRunnerClass adb pm clear adb shell am instrument -c TestClass#method2 -w com.package.name/junitRunnerClass adb pm clear Each test should be executed in isolated instrumented process and junit reports should be merged into a big one when all tests finished. That's the common idea of Orchestrator . It's just an apk which consist of only several classes and which does test run and clear for us as the same way as described above. Besides application.apk and instrumented.apk , orchestrator should be installed on the device. However, it's not the end. Orchestrator should somehow execute adb commands. Under the hood, it uses special services It's just shell client which is also represented as an apk and should be installed to the device. An official documentation and guide how to start with Orchestrator Warning Despite the fact that it does the job, this solution looks overcomplicated: We need to install +2 different apk to each emulator We delegate this job to the device instead of host machine. Devices are less reliable than host pc 2.2 Other solutions This is also possible to implement by usage of 3rd party test runners , like Marathon, Avito-Runner or Flank. Marathon and Avito-Runner clear package data without an orchestrator. They delegated this logic to host machine. 2.3 Conclusion \u2795 Does the job for us in 100% \u2796 Slow execution (can take 10+ seconds and depends on apk size) \u2796 Orchestrator \u2014 over-complicated Each adb pm clear takes some time and depends on apk size. Below you may see some gaps between the tests which represents such delay Success Only package clear does guarantee for you that data has been cleared. Marathon and Avito-Runner provide the easiest way to clear application data. You can set it just by one flag in configuration They don't use orchestrator under the hood","title":"State clearing"},{"location":"practices/state_clearing/#state-clearing","text":"This question appears as soon as you need to run more than 1 ui test.","title":"State clearing"},{"location":"practices/state_clearing/#problem","text":"We run Test1 , it performs some http requests, saves some data to files and database. When Test1 finished, Test2 will be launched. However, Test1 left some data on the device which can be a reason of Test2 failing. Solution \u2014 clear data before each test","title":"Problem:"},{"location":"practices/state_clearing/#1-within-process-clearing","text":"In this case we don't kill our application process.","title":"1. Within process clearing"},{"location":"practices/state_clearing/#11-component-from-a-real-code-base","text":"@Before fun setUp () { DI . provideLogoutCleanerInteractor (). clear () } The same component which clears data (For instance, while logout) . It should honestly clear everything in application: Databases, Files, Preferences and Runtime cache and should be executed before each test. Danger This solution is a bottleneck and it's better to avoid it at all. If LogoutCleaner broken, all of the tests will be failed","title":"1.1 Component from a real code base "},{"location":"practices/state_clearing/#12-clear-internal-storage","text":"All cache in android application stored in internal storage: /data/data/packagename/ This storage \u2014 our application sandbox and can be achieved without any permission. Common idea: to avoid usage of components from real code base and use some test rules, which do the job for us. @get : Rule val clearPreferenceRule = ClearDatabaseRule () @get : Rule val clearFilesRule = ClearFilesRule () @get : Rule val clearFilesRule = ClearPreferencesRule () They have already been implemented in Barista library, you can find them here Warning This solution won't work on 100% for you: You may have runtime cache, which is also can affect your tests Test or application process can be crashed. It prevents launch of the next tests","title":"1.2 Clear internal storage  "},{"location":"practices/state_clearing/#13-conclusion","text":"\u2795 Fast implementation \u2795 Fast execution in the same process \u2796 Don't have any guarantee that your app will be cleared properly \u2796 Application or Test process killing will break tests execution \u2796 Can be a bottleneck Use these solutions only as a temp workaround, because it won't work on perspective in a huge projects","title":"1.3 Conclusion"},{"location":"practices/state_clearing/#2-clear-package-data","text":"Idea \u2014 simulate the same behavior when user press clear data in application settings. Application process will be cleared in that state, our application will be started in a cold start.","title":"2. Clear package data"},{"location":"practices/state_clearing/#21-orchestrator","text":"Basically it is possible to have cleared state, if you would execute your tests like this: adb shell am instrument -c TestClass#method1 -w com.package.name/junitRunnerClass adb pm clear adb shell am instrument -c TestClass#method2 -w com.package.name/junitRunnerClass adb pm clear Each test should be executed in isolated instrumented process and junit reports should be merged into a big one when all tests finished. That's the common idea of Orchestrator . It's just an apk which consist of only several classes and which does test run and clear for us as the same way as described above. Besides application.apk and instrumented.apk , orchestrator should be installed on the device. However, it's not the end. Orchestrator should somehow execute adb commands. Under the hood, it uses special services It's just shell client which is also represented as an apk and should be installed to the device. An official documentation and guide how to start with Orchestrator Warning Despite the fact that it does the job, this solution looks overcomplicated: We need to install +2 different apk to each emulator We delegate this job to the device instead of host machine. Devices are less reliable than host pc","title":"2.1 Orchestrator"},{"location":"practices/state_clearing/#22-other-solutions","text":"This is also possible to implement by usage of 3rd party test runners , like Marathon, Avito-Runner or Flank. Marathon and Avito-Runner clear package data without an orchestrator. They delegated this logic to host machine.","title":"2.2 Other solutions"},{"location":"practices/state_clearing/#23-conclusion","text":"\u2795 Does the job for us in 100% \u2796 Slow execution (can take 10+ seconds and depends on apk size) \u2796 Orchestrator \u2014 over-complicated Each adb pm clear takes some time and depends on apk size. Below you may see some gaps between the tests which represents such delay Success Only package clear does guarantee for you that data has been cleared. Marathon and Avito-Runner provide the easiest way to clear application data. You can set it just by one flag in configuration They don't use orchestrator under the hood","title":"2.3 Conclusion"},{"location":"practices/test_runners_review/","text":"Test runners Test runner is responsible for tests run and providing test result for us. AndroidJunitRunner \u2014 Official solution and low-level instrument. It requires a lot of effort from engineers to run tests on CI and make them stable. It's worth to mention \u2014 tools are getting better year by year. However, some basic functionality still doesn't work from the box properly. 1. Problems with AndroidJunitRunner: Overcomplicated solution with clearing It would be good to have only one flag which does application clearing for us. It exists, however to have scalability on CI and opportunity to use filters, you still have to install test-services.apk and orchestrator.apk to each device manually Impossibility to scale As soon as you started your tests, it's impossible to connect more devices to tests run on fly Impossibility to prevent flakiness Flakiness is one of the main problems in instrumented testing. Test runner should play role as a latest flakiness protection level, like support retries from the box or other strategies Impossibility to validate flakiness Flakiness can be validated by running each test multiple times, and if test pass N/N, it's not flaky. It would be great to launch each test 100 times by one command Poor test report Default test report doesn't show any useful information. As an engineer, I want to see a video of the test, logs and to make sure that test hasn't been retried. Otherwise, I'd like to see retries and each retry video and logs. Impossibility to retry It's possible to do only via special test rule which does retry for us. However, it's up to test runner to retry each test, as instrumented process can be crashed and device less reliable than host machine. Also, it should be possible to define maximum retry count: Imagine, your application crashed on start. We shouldn't retry each test in that case because there is no sense to overload build agents on CI. Impossibility to record a video It's possible to achieve and implement manually, however It would be really great to have such functionality from the box Almost all of that problems possible to solve, but it can take weeks or even months of your time. Beside running tests, you also need to care about writing tests which is challenging as well. It would be great to have that problems solved from the box 2. Open source test runners All of them used AndroidJunitRunner under the hood, as it's the only possibility tun run instrumented tests. 2.1 Marathon Powerful and the most pragmatic test runner. All you need to do it's just to connect devices to adb , and Marathon will do the whole job for you. \u2795 CLI, Gradle Plugin \u2795 Easy data clearing (without an Orchestrator) \u2795 Flexible configuration with filters \u2795 Flakiness strategies \u2795 Smart retries with a quota \u2795 Screenshots & Video from the box \u2795 Improved test report with video & logs \u2795 Possibility to connect devices on fly \u2795 Sync/Pull files from the device after test run \u2795 Basic Allure support from the box \u2795 adb replacement: Adam \u2795 Cross-platform (iOS support) \u2796 Doesn't support auto-scaling (But from the other perspective, it's not a test runner responsibility) Documentation 2.2 Avito Test Runner Powerful test runner. Works directly with Kubernetes \u2795 Easy data clearing (without an Orchestrator) \u2795 Auto-scaling on fly (There is a coroutine in the background which tries to connect more devices) \u2795 Retries \u2796 Complicated adoption This test runner has been using by Avito company for 4+ years and runs thousands tests every day. It's not as powerful as Marathon, however it doesn't have an analogue in terms of auto scaling from the box. If you want to run your UI tests on pull requests in a large teams, this test runner is one of the best option. Engineers from Avito are ready to help with adoption. You can contact to Dmitriy Voronin Documentation 2.3 Fork //To be done 2.4 Flank //To be done 2.5 Flade //To be done 2.6 Spoon Deprecated and not maintained anymore. Do not use it 2.7 Composer Deprecated and not maintained anymore. Do not use it","title":"Test runners"},{"location":"practices/test_runners_review/#test-runners","text":"Test runner is responsible for tests run and providing test result for us. AndroidJunitRunner \u2014 Official solution and low-level instrument. It requires a lot of effort from engineers to run tests on CI and make them stable. It's worth to mention \u2014 tools are getting better year by year. However, some basic functionality still doesn't work from the box properly.","title":"Test runners"},{"location":"practices/test_runners_review/#1-problems-with-androidjunitrunner","text":"Overcomplicated solution with clearing It would be good to have only one flag which does application clearing for us. It exists, however to have scalability on CI and opportunity to use filters, you still have to install test-services.apk and orchestrator.apk to each device manually Impossibility to scale As soon as you started your tests, it's impossible to connect more devices to tests run on fly Impossibility to prevent flakiness Flakiness is one of the main problems in instrumented testing. Test runner should play role as a latest flakiness protection level, like support retries from the box or other strategies Impossibility to validate flakiness Flakiness can be validated by running each test multiple times, and if test pass N/N, it's not flaky. It would be great to launch each test 100 times by one command Poor test report Default test report doesn't show any useful information. As an engineer, I want to see a video of the test, logs and to make sure that test hasn't been retried. Otherwise, I'd like to see retries and each retry video and logs. Impossibility to retry It's possible to do only via special test rule which does retry for us. However, it's up to test runner to retry each test, as instrumented process can be crashed and device less reliable than host machine. Also, it should be possible to define maximum retry count: Imagine, your application crashed on start. We shouldn't retry each test in that case because there is no sense to overload build agents on CI. Impossibility to record a video It's possible to achieve and implement manually, however It would be really great to have such functionality from the box Almost all of that problems possible to solve, but it can take weeks or even months of your time. Beside running tests, you also need to care about writing tests which is challenging as well. It would be great to have that problems solved from the box","title":"1. Problems with AndroidJunitRunner:"},{"location":"practices/test_runners_review/#2-open-source-test-runners","text":"All of them used AndroidJunitRunner under the hood, as it's the only possibility tun run instrumented tests.","title":"2. Open source test runners"},{"location":"practices/test_runners_review/#21-marathon","text":"Powerful and the most pragmatic test runner. All you need to do it's just to connect devices to adb , and Marathon will do the whole job for you. \u2795 CLI, Gradle Plugin \u2795 Easy data clearing (without an Orchestrator) \u2795 Flexible configuration with filters \u2795 Flakiness strategies \u2795 Smart retries with a quota \u2795 Screenshots & Video from the box \u2795 Improved test report with video & logs \u2795 Possibility to connect devices on fly \u2795 Sync/Pull files from the device after test run \u2795 Basic Allure support from the box \u2795 adb replacement: Adam \u2795 Cross-platform (iOS support) \u2796 Doesn't support auto-scaling (But from the other perspective, it's not a test runner responsibility) Documentation","title":"2.1 Marathon"},{"location":"practices/test_runners_review/#22-avito-test-runner","text":"Powerful test runner. Works directly with Kubernetes \u2795 Easy data clearing (without an Orchestrator) \u2795 Auto-scaling on fly (There is a coroutine in the background which tries to connect more devices) \u2795 Retries \u2796 Complicated adoption This test runner has been using by Avito company for 4+ years and runs thousands tests every day. It's not as powerful as Marathon, however it doesn't have an analogue in terms of auto scaling from the box. If you want to run your UI tests on pull requests in a large teams, this test runner is one of the best option. Engineers from Avito are ready to help with adoption. You can contact to Dmitriy Voronin Documentation","title":"2.2 Avito Test Runner"},{"location":"practices/test_runners_review/#23-fork","text":"//To be done","title":"2.3 Fork"},{"location":"practices/test_runners_review/#24-flank","text":"//To be done","title":"2.4 Flank"},{"location":"practices/test_runners_review/#25-flade","text":"//To be done","title":"2.5 Flade"},{"location":"practices/test_runners_review/#26-spoon","text":"Deprecated and not maintained anymore. Do not use it","title":"2.6 Spoon"},{"location":"practices/test_runners_review/#27-composer","text":"Deprecated and not maintained anymore. Do not use it","title":"2.7 Composer"}]}